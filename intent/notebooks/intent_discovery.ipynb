{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent discovery in the Banking77 dataset\n",
    "\n",
    "* Build an NLU component\n",
    "    * CKY parser (dynamic programming, CFG algo)\n",
    "        * TO DO: search for production-grade library\n",
    "\n",
    "* Impact\n",
    "    * dataset automatic labelling --> reduce labor intensive annotation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup  \n",
    "### Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     /Users/steeve_laquitaine/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
    "\n",
    "# text preprocessing\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "nltk.download('punkt') # 13 MB zip containing pretrained punkt sentence tokenizer (Kiss and Strunk, 2006)\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_path = \"/Users/steeve_laquitaine/desktop/CodeHub/intent/intent/\"\n",
    "train_data_path = proj_path + \"data/01_raw/banking77/train.csv\"\n",
    "test_data_path = proj_path + \"data/01_raw/banking77/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most public corpora found had little data, except a task-oriented banking dataset Banking77. So we use it as a benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data  = pd.read_csv(train_data_path)\n",
    "test_data  = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text      category\n",
       "0                     I am still waiting on my card?  card_arrival\n",
       "1  What can I do if my card still hasn't arrived ...  card_arrival\n",
       "2  I have been waiting over a week. Is the card s...  card_arrival\n",
       "3  Can I track my card while it is in the process...  card_arrival\n",
       "4  How do I know if I will get my card, or if it ...  card_arrival"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am still waiting on my card?</td>\n      <td>card_arrival</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What can I do if my card still hasn't arrived ...</td>\n      <td>card_arrival</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I have been waiting over a week. Is the card s...</td>\n      <td>card_arrival</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Can I track my card while it is in the process...</td>\n      <td>card_arrival</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How do I know if I will get my card, or if it ...</td>\n      <td>card_arrival</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# preview\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text      category\n",
       "0                           How do I locate my card?  card_arrival\n",
       "1  I still have not received my new card, I order...  card_arrival\n",
       "2  I ordered a card but it has not arrived. Help ...  card_arrival\n",
       "3   Is there a way to know when my card will arrive?  card_arrival\n",
       "4                       My card has not arrived yet.  card_arrival"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>How do I locate my card?</td>\n      <td>card_arrival</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I still have not received my new card, I order...</td>\n      <td>card_arrival</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I ordered a card but it has not arrived. Help ...</td>\n      <td>card_arrival</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Is there a way to know when my card will arrive?</td>\n      <td>card_arrival</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>My card has not arrived yet.</td>\n      <td>card_arrival</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# preview\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_col_names(data:pd.DataFrame):\n",
    "    return data.rename(columns={\"text\":\"text\",\"category\":\"intent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = standardize_col_names(train_data)\n",
    "test_data = standardize_col_names(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nValue count:\n\ntext      10003\nintent    10003\ndtype: int64\n\nUnique values:\n\ntext      10003\nintent       77\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nValue count:\\n\")\n",
    "print(train_data.count())\n",
    "print(\"\\nUnique values:\\n\")\n",
    "print(train_data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                             text        intent\n",
       "0  I am still waiting on my card?  card_arrival"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>intent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am still waiting on my card?</td>\n      <td>card_arrival</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_data.head(1)"
   ]
  },
  {
   "source": [
    "# CLUSTERING"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(normalize_document) took: 1.98 secs\n\npPreview:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['still waiting card', 'card still hasnt arrived 2 weeks',\n",
       "       'waiting week card still coming', ..., 'countries getting support',\n",
       "       'cards available eu', 'countries represented'], dtype='<U309')"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# prep\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc:list):\n",
    "    \"\"\"\n",
    "    Normalize document\n",
    "\n",
    "    parameters:\n",
    "    ---------\n",
    "    doc\n",
    "\n",
    "    return\n",
    "    ------\n",
    "    doc\n",
    "\n",
    "    \"\"\"\n",
    "    # lower case and drop special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    \n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    \n",
    "    # drop stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # re-create doc from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "# time\n",
    "tic = time.time()\n",
    "\n",
    "# vectorize doc\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "# normalize doc\n",
    "norm_corpus = normalize_corpus(list(train_data['text']))\n",
    "len(norm_corpus)\n",
    "print(f\"(normalize_document) took: {round(time.time()-tic,2)} secs\")\n",
    "\n",
    "# show\n",
    "print(\"\\nPreview:\")\n",
    "\n",
    "norm_corpus"
   ]
  },
  {
   "source": [
    "# References"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "(1) https://www.nltk.org/_modules/nltk/ccg/chart.html  \n",
    "(2) https://github.com/dipanjanS/text-analytics-with-python/blob/master/New-Second-Edition/Ch07 - Text Similarity and Clustering/Ch07c - Document Clustering.ipynb  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('intent': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b321174aa8bda30359f2456b92364ad1fc4bb3682cd23b89ef7dfb1e69ab5093"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 242,
   "position": {
    "height": "40px",
    "left": "31px",
    "right": "20px",
    "top": "522px",
    "width": "351px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}