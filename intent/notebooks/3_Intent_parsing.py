# %% [markdown]
## VP intent parsing
#
# author: Steeve Laquitaine
#
# TABLE OF CONTENTS
#
# %% [markdown]
# PACKAGES
# %%
import os
from collections import defaultdict

import pandas as pd
import spacy

# %%
proj_path = "/Users/steeve_laquitaine/desktop/CodeHub/intent/"
os.chdir(proj_path)

# %% [markdown]
## PATHS
# %%
cfg_path = (
    proj_path + "intent/data/02_intermediate/cfg_25_02_2021_18_16_42.xlsx"
)
sim_path = proj_path + "intent/data/02_intermediate/sim_matrix.xlsx"
tag_path = proj_path + "intent/data/02_intermediate/tag.xlsx"

# %% [markdown]
# LOAD DATA
cfg = pd.read_excel(cfg_path)
tag = pd.read_excel(tag_path)

# %% [markdown]
## INTENT PARSING
#
# * Apply dependency parsing to each query
# * Collect intent's action (ROOT) and object (dobj)
# %%
# get verb and direct object (dependency parsing)
nlp = spacy.load("en_core_web_sm")


def to_dict_list(doc: spacy.tokens.doc.Doc):
    """Extract ROOT and dobj dependencies from a query  

    Args:
        doc (spacy.tokens.doc.Doc): a spacy Doc object
            e.g., generated by doc = nlp("track my credit card")  

    Returns:
        defauldict: [description]
            e.g., 
                [
                    defaultdict(list, {'ROOT': ['track'], 'dobj': ['card', 'me']}),
                    defaultdict(list, {'ROOT': ['expecting'], 'dobj': ['card']})
                ]
    """
    d = defaultdict(list)
    for token in doc:
        if token.dep_ == "ROOT":
            d["action"].append(token.text)
        if token.dep_ == "dobj":
            d["object"].append(token.text)
    return dict(d)


# collect each query's ROOT and dobj
intent = [to_dict_list(nlp(vp)) for vp in cfg["VP"]]
intent
